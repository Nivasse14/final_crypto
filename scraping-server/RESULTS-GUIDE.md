# üìä Guide d'Utilisation - Visualisation des R√©sultats de Scraping

## üöÄ Nouveaux Endpoints Disponibles

### 1. **Dashboard Web** (Visualisation Facile)
```
GET /dashboard
```
**Description :** Interface web pour visualiser tous les jobs et leurs r√©sultats  
**Authentification :** Aucune  
**Utilisation :** Ouvrir dans un navigateur  
**URL :** `http://localhost:3001/dashboard` (local) ou `https://votre-serveur.railway.app/dashboard`

**Fonctionnalit√©s :**
- Liste de tous les jobs avec leur statut
- Aper√ßu des premiers portefeuilles pour les jobs termin√©s
- T√©l√©chargement direct des r√©sultats JSON
- Auto-refresh toutes les 30 secondes

### 2. **R√©sultats Complets d'un Job**
```
GET /api/job-results/:jobId
```
**Description :** R√©cup√®re tous les portefeuilles scrap√©s pour un job  
**Authentification :** Bearer Token requis  
**R√©ponse :** JSON avec r√©sum√© + liste compl√®te des wallets

**Exemple :**
```bash
curl -H "Authorization: Bearer default-token" \
  "http://localhost:3001/api/job-results/test-123"
```

**Structure de r√©ponse :**
```json
{
  "job_id": "test-123",
  "status": "completed",
  "completed_at": "2025-08-04T...",
  "wallets_count": 150,
  "total_pages": 3,
  "summary": {
    "total_wallets": 150,
    "pages_scraped": 3,
    "avg_wallets_per_page": 50,
    "scraping_duration": "127s"
  },
  "wallets": [
    {
      "wallet": "ABC123...",
      "total_pnl_usd": "$12,345",
      "roi": "245%",
      "winrate": "78%",
      // ... toutes les autres colonnes
    }
  ]
}
```

### 3. **T√©l√©chargement Direct**
```
GET /download/:jobId?token=YOUR_TOKEN
```
**Description :** T√©l√©charge les r√©sultats en fichier JSON  
**Authentification :** Token en query parameter  
**Utilisation :** Lien direct t√©l√©chargeable

**Exemple :**
```
http://localhost:3001/download/test-123?token=default-token
```

### 4. **Liste de Tous les Jobs**
```
GET /api/jobs
```
**Description :** Aper√ßu de tous les jobs (sans les donn√©es compl√®tes)  
**Authentification :** Bearer Token requis

## üîÑ Workflow Complet

### 1. D√©marrer un Scraping
```bash
curl -X POST "http://localhost:3001/api/start-scraping" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer default-token" \
  -d '{
    "jobId": "mon-job-123",
    "url": "https://dune.com/queries/3398959/5690442"
  }'
```

**R√©ponse am√©lior√©e :**
```json
{
  "success": true,
  "job_id": "mon-job-123",
  "status": "started",
  "message": "Scraping job d√©marr√©",
  "created_at": "2025-08-04T...",
  "url": "https://dune.com/queries/3398959/5690442",
  "endpoints": {
    "status": "/api/job-status/mon-job-123",
    "results": "/api/job-results/mon-job-123",
    "estimated_duration": "2-5 minutes"
  }
}
```

### 2. Suivre le Statut
```bash
curl -H "Authorization: Bearer default-token" \
  "http://localhost:3001/api/job-status/mon-job-123"
```

### 3. R√©cup√©rer les R√©sultats
```bash
# M√©thode 1: API JSON
curl -H "Authorization: Bearer default-token" \
  "http://localhost:3001/api/job-results/mon-job-123" > results.json

# M√©thode 2: Dashboard web
open "http://localhost:3001/dashboard"

# M√©thode 3: T√©l√©chargement direct
curl "http://localhost:3001/download/mon-job-123?token=default-token" \
  -o "wallets-mon-job-123.json"
```

## üß™ Script de Test Automatis√©

Utilisez le script de test complet :
```bash
cd /Users/helenemounissamy/scanDune/scraping-server
./test-endpoints.sh
```

Ce script va :
1. Tester la sant√© du serveur
2. D√©marrer un job de scraping
3. Suivre le statut en temps r√©el
4. R√©cup√©rer et afficher les r√©sultats
5. Sauvegarder les donn√©es dans un fichier JSON

## üì± Interface Web vs API

### **Dashboard Web** (Recommand√© pour Debug)
- ‚úÖ Facile d'utilisation
- ‚úÖ Visualisation en temps r√©el
- ‚úÖ Aucune authentification
- ‚úÖ Auto-refresh automatique
- ‚úÖ Aper√ßu des donn√©es

### **API JSON** (Recommand√© pour Int√©gration)
- ‚úÖ Donn√©es compl√®tes
- ‚úÖ Programmable
- ‚úÖ S√©curis√© (authentification)
- ‚úÖ Format standardis√©

## üîß Configuration Local vs Production

### **Local (Test):**
```bash
# D√©marrer le serveur
cd /Users/helenemounissamy/scanDune/scraping-server
node server.js

# Acc√©der au dashboard
open "http://localhost:3001/dashboard"
```

### **Production (Railway):**
```bash
# Dashboard en ligne
open "https://votre-app.railway.app/dashboard"

# API en ligne
curl -H "Authorization: Bearer your-token" \
  "https://votre-app.railway.app/api/job-results/job-id"
```

## üìä Format des Donn√©es de Portefeuilles

Chaque wallet scraped contient :
```json
{
  "wallet": "Address du wallet",
  "solscan": "Lien Solscan",
  "gmgn": "Lien GMGN", 
  "cielo": "Lien Cielo",
  "wallet_pnl_link": "Lien PnL",
  "wallet_pnl": "PnL du wallet",
  "total_bought_usd": "Total achet√© en USD",
  "total_pnl_usd": "PnL total en USD",
  "roi": "Return on Investment",
  "mroi": "Modified ROI",
  "invalids": "Transactions invalides",
  "tokens": "Nombre de tokens",
  "nosells": "No sells",
  "losses": "Pertes",
  "nulls": "Nulls",
  "wins": "Gains",
  "winrate": "Taux de r√©ussite",
  "w2x": "Wins 2x",
  "w10x": "Wins 10x", 
  "w100x": "Wins 100x",
  "scalps": "Scalps",
  "scalp_ratio": "Ratio de scalp",
  "bal": "Balance",
  "bal_ratio": "Ratio de balance",
  "last_trade": "Dernier trade",
  "trade_days": "Jours de trading",
  "trade_nums": "Nombre de trades",
  "scraped_at": "Timestamp du scraping"
}
```

Maintenant vous avez une visibilit√© compl√®te sur vos donn√©es scrap√©es ! üéâ
