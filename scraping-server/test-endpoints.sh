#!/bin/bash

echo "üß™ Test des endpoints du serveur de scraping"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

# Configuration
SERVER_URL="${1:-http://localhost:3001}"
AUTH_TOKEN="${2:-default-token}"
JOB_ID="test-$(date +%s)"
DUNE_URL="https://dune.com/queries/3398959/5690442"

echo "üîß Configuration:"
echo "   Serveur: $SERVER_URL"
echo "   Job ID: $JOB_ID"
echo ""

# Test 1: V√©rifier la sant√© du serveur
echo "1Ô∏è‚É£ Test de sant√© du serveur..."
curl -s "$SERVER_URL/health" | jq '.'
echo ""

# Test 2: Lister les jobs existants
echo "2Ô∏è‚É£ Liste des jobs existants..."
curl -s -H "Authorization: Bearer $AUTH_TOKEN" "$SERVER_URL/api/jobs" | jq '.'
echo ""

# Test 3: D√©marrer un nouveau job
echo "3Ô∏è‚É£ D√©marrage d'un nouveau job de scraping..."
START_RESPONSE=$(curl -s -X POST "$SERVER_URL/api/start-scraping" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $AUTH_TOKEN" \
  -d "{
    \"jobId\": \"$JOB_ID\",
    \"url\": \"$DUNE_URL\",
    \"callback_url\": \"$SERVER_URL/webhook-test\"
  }")

echo "$START_RESPONSE" | jq '.'
echo ""

# Test 4: V√©rifier le statut du job
echo "4Ô∏è‚É£ V√©rification du statut du job..."
sleep 2
curl -s -H "Authorization: Bearer $AUTH_TOKEN" "$SERVER_URL/api/job-status/$JOB_ID" | jq '.'
echo ""

# Test 5: Attendre et r√©cup√©rer les r√©sultats
echo "5Ô∏è‚É£ Attente de la fin du scraping (max 3 minutes)..."
MAX_ATTEMPTS=36  # 3 minutes = 36 * 5 secondes
ATTEMPT=1

while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
    STATUS_RESPONSE=$(curl -s -H "Authorization: Bearer $AUTH_TOKEN" "$SERVER_URL/api/job-status/$JOB_ID")
    STATUS=$(echo "$STATUS_RESPONSE" | jq -r '.status')
    
    echo "   Tentative $ATTEMPT/$MAX_ATTEMPTS - Statut: $STATUS"
    
    if [ "$STATUS" = "completed" ]; then
        echo "‚úÖ Job termin√© avec succ√®s !"
        break
    elif [ "$STATUS" = "failed" ]; then
        echo "‚ùå Job √©chou√© !"
        echo "$STATUS_RESPONSE" | jq '.'
        exit 1
    fi
    
    sleep 5
    ATTEMPT=$((ATTEMPT + 1))
done

if [ $ATTEMPT -gt $MAX_ATTEMPTS ]; then
    echo "‚è∞ Timeout atteint, r√©cup√©ration du statut final..."
    curl -s -H "Authorization: Bearer $AUTH_TOKEN" "$SERVER_URL/api/job-status/$JOB_ID" | jq '.'
else
    # Test 6: R√©cup√©rer les r√©sultats complets
    echo ""
    echo "6Ô∏è‚É£ R√©cup√©ration des r√©sultats complets..."
    RESULTS_RESPONSE=$(curl -s -H "Authorization: Bearer $AUTH_TOKEN" "$SERVER_URL/api/job-results/$JOB_ID")
    
    # Afficher le r√©sum√©
    echo "$RESULTS_RESPONSE" | jq '{
        job_id: .job_id,
        status: .status,
        completed_at: .completed_at,
        wallets_count: .wallets_count,
        summary: .summary
    }'
    
    echo ""
    echo "7Ô∏è‚É£ Aper√ßu des premiers portefeuilles (5 premiers)..."
    echo "$RESULTS_RESPONSE" | jq '.wallets[0:5] | map({
        wallet: .wallet,
        total_pnl_usd: .total_pnl_usd,
        roi: .roi,
        winrate: .winrate,
        tokens: .tokens
    })'
    
    # Sauvegarder les r√©sultats complets
    echo ""
    echo "üíæ Sauvegarde des r√©sultats complets..."
    echo "$RESULTS_RESPONSE" > "scraping-results-$JOB_ID.json"
    echo "   Fichier sauv√©: scraping-results-$JOB_ID.json"
    
    WALLET_COUNT=$(echo "$RESULTS_RESPONSE" | jq -r '.wallets_count')
    echo "   Total portefeuilles: $WALLET_COUNT"
fi

echo ""
echo "8Ô∏è‚É£ √âtat final de tous les jobs..."
curl -s -H "Authorization: Bearer $AUTH_TOKEN" "$SERVER_URL/api/jobs" | jq '.'

echo ""
echo "‚úÖ Test termin√© !"
